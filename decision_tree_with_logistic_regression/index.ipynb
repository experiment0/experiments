{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дерево решений с использованием логистической регрессии в качестве разделяющей плоскости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from classes.DecisionTree import (\n",
    "    DecisionTreeRegressor, \n",
    "    DecisionTreeClassifier,\n",
    ")\n",
    "from classes.DecisionTreeWithLogisticRegression import (\n",
    "    DecisionTreeWithLogisticRegression\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Примечание**. При выполнении поиска оптимальных параметров сплита \\\n",
    "возможно возникновение такой ситуации, когда взвешенная неоднородность для двух разных наборов параметров \\\n",
    "будет одинаковой. \\\n",
    "В собственной реализации такие ситуации не учитываются: \\\n",
    "выбирается первый встретившийся вариант параметров с наименьшей взвешенной неоднородностью.\n",
    ">\n",
    "> В `sklearn` такие случаи обрабатываются следующим образом: \\\n",
    "из всех наборов параметров разбиения, для которых неоднородность после сплита минимальна из возможных \\\n",
    "и при этом одинакова, случайным образом выбирается только один этих наборов. \\\n",
    "Поэтому иногда деревья, полученные с помощью кода из собственного класса и деревья из `sklearn` могут не совпадать. \\\n",
    "Для получения этого совпадения при работе с деревьями из sklearn задается параметр `random_state`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений для регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MYCT</th>\n",
       "      <th>MMIN</th>\n",
       "      <th>MMAX</th>\n",
       "      <th>CACH</th>\n",
       "      <th>CHMIN</th>\n",
       "      <th>CHMAX</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MYCT    MMIN     MMAX   CACH  CHMIN  CHMAX  class\n",
       "0  125.0   256.0   6000.0  256.0   16.0  128.0  198.0\n",
       "1   29.0  8000.0  32000.0   32.0    8.0   32.0  269.0\n",
       "2   29.0  8000.0  32000.0   32.0    8.0   32.0  220.0\n",
       "3   29.0  8000.0  32000.0   32.0    8.0   32.0  172.0\n",
       "4   29.0  8000.0  16000.0   32.0    8.0   16.0  132.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для примера возьмем данные о производительности компьютеров\n",
    "cpu_data_full = fetch_openml(name='machine_cpu')\n",
    "cpu_data = cpu_data_full['frame']\n",
    "cpu_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание признаков**\n",
    "- `MYCT` - время цикла машины в наносекундах (целое число)\n",
    "- `MMIN` - минимальный объем основной памяти в килобайтах (целое число)\n",
    "- `MMAX` - максимальный объем основной памяти в килобайтах (целое число)\n",
    "- `CACH` - кэш-память в килобайтах (целое число)\n",
    "- `CHMIN` - минимальный объем каналов в единицах (целое число)\n",
    "- `CHMAX` - максимальный объем каналов в единицах (целое число)\n",
    "- `class` - опубликованная относительная производительность (целое число) (целевая переменная)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209 entries, 0 to 208\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   MYCT    209 non-null    float64\n",
      " 1   MMIN    209 non-null    float64\n",
      " 2   MMAX    209 non-null    float64\n",
      " 3   CACH    209 non-null    float64\n",
      " 4   CHMIN   209 non-null    float64\n",
      " 5   CHMAX   209 non-null    float64\n",
      " 6   class   209 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 11.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на характеристики признаков\n",
    "cpu_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все данные числовые, пропусков нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки\n",
    "X = cpu_data.drop(['class'], axis = 1)\n",
    "# целевой признак\n",
    "y = cpu_data['class']\n",
    "\n",
    "# разделяем на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение дерева решений с помощью собственного класса `DecisionTreeRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_2 <= 22485.00\n",
      "|   |--- feature_3 <= 27.00\n",
      "|   |   |--- feature_2 <= 10000.00\n",
      "|   |   |   |--- value: [32.32142857142857]\n",
      "|   |   |--- feature_2 > 10000.00\n",
      "|   |   |   |--- value: [71.31818181818181]\n",
      "|   |--- feature_3 > 27.00\n",
      "|   |   |--- feature_3 <= 96.50\n",
      "|   |   |   |--- value: [106.41666666666667]\n",
      "|   |   |--- feature_3 > 96.50\n",
      "|   |   |   |--- value: [231.4]\n",
      "|--- feature_2 > 22485.00\n",
      "|   |--- feature_4 <= 14.00\n",
      "|   |   |--- feature_4 <= 7.00\n",
      "|   |   |   |--- value: [143.6]\n",
      "|   |   |--- feature_4 > 7.00\n",
      "|   |   |   |--- value: [252.7]\n",
      "|   |--- feature_4 > 14.00\n",
      "|   |   |--- feature_2 <= 48000.00\n",
      "|   |   |   |--- value: [433.6]\n",
      "|   |   |--- feature_2 > 48000.00\n",
      "|   |   |   |--- value: [636.0]\n",
      "\n",
      "MAPE score: 0.5664946432356037\n"
     ]
    }
   ],
   "source": [
    "# создаем объект класса для построения модели дерева решений\n",
    "dtr_model = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "# обучаем\n",
    "dtr_model.fit(X_train, y_train)\n",
    "# печатаем дерево\n",
    "dtr_model.print_decision_tree()\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtr_model.predict(X_test)\n",
    "# выводим метрику MAPE (Mean Absolute Percent Error)\n",
    "print()\n",
    "print('MAPE score:', metrics.mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение дерева решений с помощью класса из `sklearn.tree.DecisionTreeRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_2 <= 22485.00\n",
      "|   |--- feature_3 <= 27.00\n",
      "|   |   |--- feature_2 <= 10000.00\n",
      "|   |   |   |--- value: [32.32]\n",
      "|   |   |--- feature_2 >  10000.00\n",
      "|   |   |   |--- value: [71.32]\n",
      "|   |--- feature_3 >  27.00\n",
      "|   |   |--- feature_3 <= 96.50\n",
      "|   |   |   |--- value: [106.42]\n",
      "|   |   |--- feature_3 >  96.50\n",
      "|   |   |   |--- value: [231.40]\n",
      "|--- feature_2 >  22485.00\n",
      "|   |--- feature_4 <= 14.00\n",
      "|   |   |--- feature_4 <= 7.00\n",
      "|   |   |   |--- value: [143.60]\n",
      "|   |   |--- feature_4 >  7.00\n",
      "|   |   |   |--- value: [252.70]\n",
      "|   |--- feature_4 >  14.00\n",
      "|   |   |--- feature_2 <= 48000.00\n",
      "|   |   |   |--- value: [433.60]\n",
      "|   |   |--- feature_2 >  48000.00\n",
      "|   |   |   |--- value: [636.00]\n",
      "\n",
      "\n",
      "MAPE score: 0.5664946432356037\n"
     ]
    }
   ],
   "source": [
    "# инициализируем модель дерева решений\n",
    "dtr_model = tree.DecisionTreeRegressor(\n",
    "    max_depth=3,\n",
    "    criterion='squared_error', # критерий информативности\n",
    "    random_state=0 # генератор случайных чисел для совпадения результатов\n",
    ")\n",
    "\n",
    "# обучаем\n",
    "dtr_model.fit(X_train, y_train)\n",
    "\n",
    "# выводим дерево решений на экран в виде списка условий\n",
    "print(tree.export_text(decision_tree=dtr_model))\n",
    "\n",
    "# Вычисляем значения информативности признаков\n",
    "#print(dtr_model.feature_importances_)\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtr_model.predict(X_test)\n",
    "# выводим метрику MAPE (Mean Absolute Percent Error)\n",
    "print()\n",
    "print('MAPE score:', metrics.mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Получились одинаковые деревья решений и одинаковая метрика `MAPE`. \\\n",
    "Из чего можно сделать вывод, что собственный алгоритм для регрессии реализован в первом приближении корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation_number</th>\n",
       "      <th>Hospital_identification_number_for_blood_sample</th>\n",
       "      <th>Age_of_patient</th>\n",
       "      <th>Date_that_blood_sample_was_taken</th>\n",
       "      <th>ml</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1027</td>\n",
       "      <td>30</td>\n",
       "      <td>100078</td>\n",
       "      <td>167.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>364.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1013</td>\n",
       "      <td>41</td>\n",
       "      <td>100078</td>\n",
       "      <td>104.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>245.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1324</td>\n",
       "      <td>22</td>\n",
       "      <td>80079</td>\n",
       "      <td>30.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>284.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1332</td>\n",
       "      <td>22</td>\n",
       "      <td>80079</td>\n",
       "      <td>44.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>172.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>966</td>\n",
       "      <td>20</td>\n",
       "      <td>100078</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>198.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Observation_number  Hospital_identification_number_for_blood_sample  \\\n",
       "0                  1                                             1027   \n",
       "1                  1                                             1013   \n",
       "2                  1                                             1324   \n",
       "3                  2                                             1332   \n",
       "4                  1                                              966   \n",
       "\n",
       "   Age_of_patient  Date_that_blood_sample_was_taken     ml     m2    m3  \\\n",
       "0              30                            100078  167.0   89.0  25.6   \n",
       "1              41                            100078  104.0   81.0  26.8   \n",
       "2              22                             80079   30.0  108.0   8.8   \n",
       "3              22                             80079   44.0  104.0  17.4   \n",
       "4              20                            100078   65.0   87.0  23.8   \n",
       "\n",
       "      m4    class  \n",
       "0  364.0  carrier  \n",
       "1  245.0  carrier  \n",
       "2  284.0  carrier  \n",
       "3  172.0  carrier  \n",
       "4  198.0  carrier  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для примера возьмем данные об анализах крови на редкое генетическое заболевание\n",
    "biomed_data_full = fetch_openml(name='biomed')\n",
    "biomed_data = biomed_data_full['frame']\n",
    "biomed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание признаков**\n",
    "\n",
    "- `Observation_number` - номер наблюдения\n",
    "- `Hospital_identification_number_for_blood_sample` - идентификационный номер больницы для образца крови\n",
    "- `Age_of_patient` - возраст пациента\n",
    "- `Date_that_blood_sample_was_taken` - дата взятия образца крови\n",
    "- `M1` - сывороточная креатинкиназа.\n",
    "- `M2` - гемопексин.\n",
    "- `M3` - пируваткиназа.\n",
    "- `M4` - лактатдегидрогеназа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удалим лишние признаки\n",
    "biomed_data.drop(\n",
    "    columns=[\n",
    "        'Observation_number', \n",
    "        'Hospital_identification_number_for_blood_sample',\n",
    "        'Date_that_blood_sample_was_taken',\n",
    "    ], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# удалим дубликаты\n",
    "biomed_data.dropna(inplace=True)\n",
    "\n",
    "# переведем целевой признак в числовой\n",
    "biomed_data['class'] = biomed_data['class'].apply(lambda value: 1 if value == 'carrier' else 0)\n",
    "biomed_data['class'] = biomed_data['class'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 194 entries, 0 to 208\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age_of_patient  194 non-null    int64  \n",
      " 1   ml              194 non-null    float64\n",
      " 2   m2              194 non-null    float64\n",
      " 3   m3              194 non-null    float64\n",
      " 4   m4              194 non-null    float64\n",
      " 5   class           194 non-null    int32  \n",
      "dtypes: float64(4), int32(1), int64(1)\n",
      "memory usage: 9.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на характеристики признаков\n",
    "biomed_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все признаки числовые, пропусков нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки\n",
    "X = biomed_data.drop(['class'], axis = 1)\n",
    "# целевой признак\n",
    "y = biomed_data['class']\n",
    "\n",
    "# разделяем на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение дерева решений с помощью собственного класса `DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_1 <= 56.00\n",
      "|   |--- feature_0 <= 40.50\n",
      "|   |   |--- feature_4 <= 269.00\n",
      "|   |   |   |--- value: [0]\n",
      "|   |   |--- feature_4 > 269.00\n",
      "|   |   |   |--- value: [1]\n",
      "|   |--- feature_0 > 40.50\n",
      "|   |   |--- value: [1]\n",
      "|--- feature_1 > 56.00\n",
      "|   |--- feature_2 <= 83.15\n",
      "|   |   |--- feature_4 <= 219.00\n",
      "|   |   |   |--- value: [0]\n",
      "|   |   |--- feature_4 > 219.00\n",
      "|   |   |   |--- value: [1]\n",
      "|   |--- feature_2 > 83.15\n",
      "|   |   |--- value: [1]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        35\n",
      "           1       0.71      0.71      0.71        14\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.80      0.80      0.80        49\n",
      "weighted avg       0.84      0.84      0.84        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создаем объект класса для построения модели дерева решений\n",
    "dtc_model = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# обучаем\n",
    "dtc_model.fit(X_train, y_train)\n",
    "# печатаем дерево\n",
    "dtc_model.print_decision_tree()\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtc_model.predict(X_test)\n",
    "# выводим общий отчет по метрикам\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение дерева решений с помощью класса из `sklearn.tree.DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_1 <= 56.00\n",
      "|   |--- feature_0 <= 40.50\n",
      "|   |   |--- feature_4 <= 269.00\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- feature_4 >  269.00\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- feature_0 >  40.50\n",
      "|   |   |--- class: 1\n",
      "|--- feature_1 >  56.00\n",
      "|   |--- feature_2 <= 83.15\n",
      "|   |   |--- feature_4 <= 219.00\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- feature_4 >  219.00\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- feature_2 >  83.15\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        35\n",
      "           1       0.71      0.71      0.71        14\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.80      0.80      0.80        49\n",
      "weighted avg       0.84      0.84      0.84        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# инициализируем модель дерева решений\n",
    "dtc_model = tree.DecisionTreeClassifier(\n",
    "    max_depth=3,\n",
    "    criterion='entropy', # критерий информативности\n",
    "    random_state=42 # генератор случайных чисел для совпадения результатов\n",
    ")\n",
    "\n",
    "# обучаем\n",
    "dtc_model.fit(X_train, y_train)\n",
    "\n",
    "# выводим дерево решений на экран в виде списка условий\n",
    "print(tree.export_text(decision_tree=dtc_model))\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtc_model.predict(X_test)\n",
    "# выводим общий отчет по метрикам\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Получились одинаковые деревья решений и одинаковые метрики. \\\n",
    "Из чего можно сделать вывод, что собственный алгоритм для классификации реализован в первом приближении корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений с использованием логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классе `./classes/DecisionTreeWithLogisticRegression.py` \\\n",
    "реализован алгоритм дерева решения для классификации, \\\n",
    "аналогично, как в классе `./classes/DecisionTree.py`\n",
    "\n",
    "Но в качестве плоскости, разделяющей выборки на 2 части,\\\n",
    "взят не предикат, а логистическая регрессия.\n",
    "\n",
    "Посмотрим, какой это даст результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\exper\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\range.py:385\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m dtlr_model \u001b[38;5;241m=\u001b[39m DecisionTreeWithLogisticRegression(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# обучаем\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdtlr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# печатаем дерево\u001b[39;00m\n\u001b[0;32m      7\u001b[0m dtlr_model\u001b[38;5;241m.\u001b[39mprint_decision_tree()\n",
      "File \u001b[1;32mc:\\001\\Учеба\\DataSainse\\Projects\\experiments\\decision_tree_with_logistic_regression\\classes\\DecisionTreeWithLogisticRegression.py:298\u001b[0m, in \u001b[0;36mDecisionTreeWithLogisticRegression.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Строит и запоминает дерево решений для обучающей выборки\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    X (pd.DataFrame): данные обучающей выборки\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m    y (pd.Series): истинные значения целевой переменной для обучающей выборки\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# строим дерево решений\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m decision_tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__build_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# запоминаем его для дальнейших предсказаний\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_tree \u001b[38;5;241m=\u001b[39m decision_tree\n",
      "File \u001b[1;32mc:\\001\\Учеба\\DataSainse\\Projects\\experiments\\decision_tree_with_logistic_regression\\classes\\DecisionTreeWithLogisticRegression.py:262\u001b[0m, in \u001b[0;36mDecisionTreeWithLogisticRegression.__build_decision_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    260\u001b[0m X_left, y_left, X_right, y_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__split(X, y, prediction)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# вызываем данную функцию рекурсивно и формируем левую дочернюю вершину\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m left_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__build_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# вызываем данную функцию рекурсивно и формируем правую дочернюю вершину\u001b[39;00m\n\u001b[0;32m    264\u001b[0m right_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__build_decision_tree(X_right, y_right, depth)\n",
      "File \u001b[1;32mc:\\001\\Учеба\\DataSainse\\Projects\\experiments\\decision_tree_with_logistic_regression\\classes\\DecisionTreeWithLogisticRegression.py:262\u001b[0m, in \u001b[0;36mDecisionTreeWithLogisticRegression.__build_decision_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    260\u001b[0m X_left, y_left, X_right, y_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__split(X, y, prediction)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# вызываем данную функцию рекурсивно и формируем левую дочернюю вершину\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m left_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__build_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# вызываем данную функцию рекурсивно и формируем правую дочернюю вершину\u001b[39;00m\n\u001b[0;32m    264\u001b[0m right_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__build_decision_tree(X_right, y_right, depth)\n",
      "File \u001b[1;32mc:\\001\\Учеба\\DataSainse\\Projects\\experiments\\decision_tree_with_logistic_regression\\classes\\DecisionTreeWithLogisticRegression.py:264\u001b[0m, in \u001b[0;36mDecisionTreeWithLogisticRegression.__build_decision_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    262\u001b[0m left_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__build_decision_tree(X_left, y_left, depth)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# вызываем данную функцию рекурсивно и формируем правую дочернюю вершину\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m right_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__build_decision_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# формируем корневую или промежуточную вершину с левым и правым потомками\u001b[39;00m\n\u001b[0;32m    266\u001b[0m node \u001b[38;5;241m=\u001b[39m Node(\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# вершина левого потомка\u001b[39;00m\n\u001b[0;32m    268\u001b[0m     left\u001b[38;5;241m=\u001b[39mleft_node, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m     samples\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m    279\u001b[0m )\n",
      "File \u001b[1;32mc:\\001\\Учеба\\DataSainse\\Projects\\experiments\\decision_tree_with_logistic_regression\\classes\\DecisionTreeWithLogisticRegression.py:241\u001b[0m, in \u001b[0;36mDecisionTreeWithLogisticRegression.__build_decision_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# если выполняется критерий остановки деления дерева, формируем лист\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__stopping_criterion(X, y, depth):\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m#print('__stopping_criterion y.size', y.size)\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# считаем предсказание для листа\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__create_leaf_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):    \n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# формируем объект класса вершины дерева для листа\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         node \u001b[38;5;241m=\u001b[39m Node(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;66;03m# предсказание для листа\u001b[39;00m\n\u001b[0;32m    247\u001b[0m             value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m             is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    254\u001b[0m         )\n",
      "File \u001b[1;32mc:\\001\\Учеба\\DataSainse\\Projects\\experiments\\decision_tree_with_logistic_regression\\classes\\DecisionTreeWithLogisticRegression.py:216\u001b[0m, in \u001b[0;36mDecisionTreeWithLogisticRegression.__create_leaf_prediction\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Возвращает предсказание для выборки из листа дерева\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    Value_type: общее предсказание для листа\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m#if (y.size == 0):\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m#return None\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# для классификации предсказание по выборке из листа - это мода\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\exper\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\exper\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\exper\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\range.py:387\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# создаем объект класса модели\n",
    "dtlr_model = DecisionTreeWithLogisticRegression(max_depth=3)\n",
    "\n",
    "# обучаем\n",
    "dtlr_model.fit(X_train, y_train)\n",
    "# печатаем дерево\n",
    "dtlr_model.print_decision_tree()\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtlr_model.predict(X_test)\n",
    "# выводим общий отчет по метрикам\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, None}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
