{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дерево решений с использованием логистической регрессии в качестве разделяющей плоскости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Для корректной работы ссылок оглавления лучше смотреть проект здесь \\\n",
    "> https://nbviewer.org/github/experiment0/experiments/blob/main/decision_tree_with_logistic_regression/index.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление\n",
    "- [Дерево решений для регрессии](#regression_tree)\n",
    "    - [Загрузка данных](#rt_load)\n",
    "    - [Построение дерева решений с помощью собственного класса `DecisionTreeRegressor`](#rt_custom)\n",
    "    - [Построение дерева решений с помощью класса из `sklearn.tree.DecisionTreeRegressor`](#rt_sklearn)\n",
    "- [Дерево решений для классификации](#classification_tree)\n",
    "    - [Загрузка данных](#ct_load)\n",
    "    - [Построение дерева решений с помощью собственного класса `DecisionTreeClassifier`](#ct_custom)\n",
    "    - [Построение дерева решений с помощью класса из `sklearn.tree.DecisionTreeClassifier`](#ct_sklearn)\n",
    "- [Дерево решений для бинарной классификации с использованием логистической регрессии](#logistic_tree)\n",
    "- [Сравнение значений взвешенной неоднородности в первых вершинах полученных моделей для классификации](#weighted_impurity)\n",
    "- [Вывод](#result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from classes.DecisionTree import (\n",
    "    DecisionTreeRegressor, \n",
    "    DecisionTreeClassifier,\n",
    ")\n",
    "from classes.DecisionTreeWithLogisticRegression import (\n",
    "    DecisionTreeWithLogisticRegression\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Примечание**. При выполнении поиска оптимальных параметров сплита \\\n",
    "возможно возникновение такой ситуации, когда взвешенная неоднородность для двух разных наборов параметров \\\n",
    "будет одинаковой. \\\n",
    "В собственной реализации такие ситуации не учитываются: \\\n",
    "выбирается первый встретившийся вариант параметров с наименьшей взвешенной неоднородностью.\n",
    ">\n",
    "> В `sklearn` такие случаи обрабатываются следующим образом: \\\n",
    "из всех наборов параметров разбиения, для которых неоднородность после сплита минимальна из возможных \\\n",
    "и при этом одинакова, случайным образом выбирается только один этих наборов. \\\n",
    "Поэтому иногда деревья, полученные с помощью кода из собственного класса и деревья из `sklearn` могут не совпадать. \\\n",
    "Для получения этого совпадения при работе с деревьями из sklearn задается параметр `random_state`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений для регрессии <a id=\"regression_tree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных <a id=\"rt_load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MYCT</th>\n",
       "      <th>MMIN</th>\n",
       "      <th>MMAX</th>\n",
       "      <th>CACH</th>\n",
       "      <th>CHMIN</th>\n",
       "      <th>CHMAX</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MYCT    MMIN     MMAX   CACH  CHMIN  CHMAX  class\n",
       "0  125.0   256.0   6000.0  256.0   16.0  128.0  198.0\n",
       "1   29.0  8000.0  32000.0   32.0    8.0   32.0  269.0\n",
       "2   29.0  8000.0  32000.0   32.0    8.0   32.0  220.0\n",
       "3   29.0  8000.0  32000.0   32.0    8.0   32.0  172.0\n",
       "4   29.0  8000.0  16000.0   32.0    8.0   16.0  132.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для примера возьмем данные о производительности компьютеров\n",
    "cpu_data_full = fetch_openml(name='machine_cpu')\n",
    "cpu_data = cpu_data_full['frame']\n",
    "cpu_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание признаков**\n",
    "- `MYCT` - время цикла машины в наносекундах (целое число)\n",
    "- `MMIN` - минимальный объем основной памяти в килобайтах (целое число)\n",
    "- `MMAX` - максимальный объем основной памяти в килобайтах (целое число)\n",
    "- `CACH` - кэш-память в килобайтах (целое число)\n",
    "- `CHMIN` - минимальный объем каналов в единицах (целое число)\n",
    "- `CHMAX` - максимальный объем каналов в единицах (целое число)\n",
    "- `class` - опубликованная относительная производительность (целое число) (целевая переменная)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209 entries, 0 to 208\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   MYCT    209 non-null    float64\n",
      " 1   MMIN    209 non-null    float64\n",
      " 2   MMAX    209 non-null    float64\n",
      " 3   CACH    209 non-null    float64\n",
      " 4   CHMIN   209 non-null    float64\n",
      " 5   CHMAX   209 non-null    float64\n",
      " 6   class   209 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 11.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на характеристики признаков\n",
    "cpu_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все данные числовые, пропусков нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки\n",
    "X = cpu_data.drop(['class'], axis = 1)\n",
    "# целевой признак\n",
    "y = cpu_data['class']\n",
    "\n",
    "# разделяем на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение дерева решений с помощью собственного класса `DecisionTreeRegressor` <a id=\"rt_custom\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_2 <= 22485.00\n",
      "|   |--- feature_3 <= 27.00\n",
      "|   |   |--- feature_2 <= 10000.00\n",
      "|   |   |   |--- value: [32.32142857142857]\n",
      "|   |   |--- feature_2 > 10000.00\n",
      "|   |   |   |--- value: [71.31818181818181]\n",
      "|   |--- feature_3 > 27.00\n",
      "|   |   |--- feature_3 <= 96.50\n",
      "|   |   |   |--- value: [106.41666666666667]\n",
      "|   |   |--- feature_3 > 96.50\n",
      "|   |   |   |--- value: [231.4]\n",
      "|--- feature_2 > 22485.00\n",
      "|   |--- feature_4 <= 14.00\n",
      "|   |   |--- feature_4 <= 7.00\n",
      "|   |   |   |--- value: [143.6]\n",
      "|   |   |--- feature_4 > 7.00\n",
      "|   |   |   |--- value: [252.7]\n",
      "|   |--- feature_4 > 14.00\n",
      "|   |   |--- feature_2 <= 48000.00\n",
      "|   |   |   |--- value: [433.6]\n",
      "|   |   |--- feature_2 > 48000.00\n",
      "|   |   |   |--- value: [636.0]\n",
      "\n",
      "MAPE score: 0.5664946432356037\n"
     ]
    }
   ],
   "source": [
    "# создаем объект класса для построения модели дерева решений\n",
    "dtr_custom_model = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "# обучаем\n",
    "dtr_custom_model.fit(X_train, y_train)\n",
    "# печатаем дерево\n",
    "dtr_custom_model.print_decision_tree()\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtr_custom_model.predict(X_test)\n",
    "# выводим метрику MAPE (Mean Absolute Percent Error)\n",
    "print()\n",
    "print('MAPE score:', metrics.mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение дерева решений с помощью класса из `sklearn.tree.DecisionTreeRegressor` <a id=\"rt_sklearn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_2 <= 22485.00\n",
      "|   |--- feature_3 <= 27.00\n",
      "|   |   |--- feature_2 <= 10000.00\n",
      "|   |   |   |--- value: [32.32]\n",
      "|   |   |--- feature_2 >  10000.00\n",
      "|   |   |   |--- value: [71.32]\n",
      "|   |--- feature_3 >  27.00\n",
      "|   |   |--- feature_3 <= 96.50\n",
      "|   |   |   |--- value: [106.42]\n",
      "|   |   |--- feature_3 >  96.50\n",
      "|   |   |   |--- value: [231.40]\n",
      "|--- feature_2 >  22485.00\n",
      "|   |--- feature_4 <= 14.00\n",
      "|   |   |--- feature_4 <= 7.00\n",
      "|   |   |   |--- value: [143.60]\n",
      "|   |   |--- feature_4 >  7.00\n",
      "|   |   |   |--- value: [252.70]\n",
      "|   |--- feature_4 >  14.00\n",
      "|   |   |--- feature_2 <= 48000.00\n",
      "|   |   |   |--- value: [433.60]\n",
      "|   |   |--- feature_2 >  48000.00\n",
      "|   |   |   |--- value: [636.00]\n",
      "\n",
      "\n",
      "MAPE score: 0.5664946432356037\n"
     ]
    }
   ],
   "source": [
    "# инициализируем модель дерева решений\n",
    "dtr_model = tree.DecisionTreeRegressor(\n",
    "    max_depth=3,\n",
    "    criterion='squared_error', # критерий информативности\n",
    "    random_state=0 # генератор случайных чисел для совпадения результатов\n",
    ")\n",
    "\n",
    "# обучаем\n",
    "dtr_model.fit(X_train, y_train)\n",
    "\n",
    "# выводим дерево решений на экран в виде списка условий\n",
    "print(tree.export_text(decision_tree=dtr_model))\n",
    "\n",
    "# Вычисляем значения информативности признаков\n",
    "#print(dtr_model.feature_importances_)\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtr_model.predict(X_test)\n",
    "# выводим метрику MAPE (Mean Absolute Percent Error)\n",
    "print()\n",
    "print('MAPE score:', metrics.mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Получились одинаковые деревья решений и одинаковая метрика `MAPE`. \\\n",
    "Из чего можно сделать вывод, что собственный алгоритм для регрессии реализован в первом приближении корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений для классификации <a id=\"classification_tree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных <a id=\"ct_load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation_number</th>\n",
       "      <th>Hospital_identification_number_for_blood_sample</th>\n",
       "      <th>Age_of_patient</th>\n",
       "      <th>Date_that_blood_sample_was_taken</th>\n",
       "      <th>ml</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1027</td>\n",
       "      <td>30</td>\n",
       "      <td>100078</td>\n",
       "      <td>167.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>364.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1013</td>\n",
       "      <td>41</td>\n",
       "      <td>100078</td>\n",
       "      <td>104.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>245.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1324</td>\n",
       "      <td>22</td>\n",
       "      <td>80079</td>\n",
       "      <td>30.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>284.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1332</td>\n",
       "      <td>22</td>\n",
       "      <td>80079</td>\n",
       "      <td>44.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>172.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>966</td>\n",
       "      <td>20</td>\n",
       "      <td>100078</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>198.0</td>\n",
       "      <td>carrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Observation_number  Hospital_identification_number_for_blood_sample  \\\n",
       "0                  1                                             1027   \n",
       "1                  1                                             1013   \n",
       "2                  1                                             1324   \n",
       "3                  2                                             1332   \n",
       "4                  1                                              966   \n",
       "\n",
       "   Age_of_patient  Date_that_blood_sample_was_taken     ml     m2    m3  \\\n",
       "0              30                            100078  167.0   89.0  25.6   \n",
       "1              41                            100078  104.0   81.0  26.8   \n",
       "2              22                             80079   30.0  108.0   8.8   \n",
       "3              22                             80079   44.0  104.0  17.4   \n",
       "4              20                            100078   65.0   87.0  23.8   \n",
       "\n",
       "      m4    class  \n",
       "0  364.0  carrier  \n",
       "1  245.0  carrier  \n",
       "2  284.0  carrier  \n",
       "3  172.0  carrier  \n",
       "4  198.0  carrier  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для примера возьмем данные об анализах крови на редкое генетическое заболевание\n",
    "biomed_data_full = fetch_openml(name='biomed')\n",
    "biomed_data = biomed_data_full['frame']\n",
    "biomed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание признаков**\n",
    "\n",
    "- `Observation_number` - номер наблюдения\n",
    "- `Hospital_identification_number_for_blood_sample` - идентификационный номер больницы для образца крови\n",
    "- `Age_of_patient` - возраст пациента\n",
    "- `Date_that_blood_sample_was_taken` - дата взятия образца крови\n",
    "- `M1` - сывороточная креатинкиназа.\n",
    "- `M2` - гемопексин.\n",
    "- `M3` - пируваткиназа.\n",
    "- `M4` - лактатдегидрогеназа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удалим лишние признаки\n",
    "biomed_data.drop(\n",
    "    columns=[\n",
    "        'Observation_number', \n",
    "        'Hospital_identification_number_for_blood_sample',\n",
    "        'Date_that_blood_sample_was_taken',\n",
    "    ], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# удалим дубликаты\n",
    "biomed_data.dropna(inplace=True)\n",
    "\n",
    "# переведем целевой признак в числовой\n",
    "biomed_data['class'] = biomed_data['class'].apply(lambda value: 1 if value == 'carrier' else 0)\n",
    "biomed_data['class'] = biomed_data['class'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 194 entries, 0 to 208\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age_of_patient  194 non-null    int64  \n",
      " 1   ml              194 non-null    float64\n",
      " 2   m2              194 non-null    float64\n",
      " 3   m3              194 non-null    float64\n",
      " 4   m4              194 non-null    float64\n",
      " 5   class           194 non-null    int32  \n",
      "dtypes: float64(4), int32(1), int64(1)\n",
      "memory usage: 9.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на характеристики признаков\n",
    "biomed_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все признаки числовые, пропусков нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки\n",
    "X = biomed_data.drop(['class'], axis = 1)\n",
    "# целевой признак\n",
    "y = biomed_data['class']\n",
    "\n",
    "# разделяем на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение дерева решений с помощью собственного класса `DecisionTreeClassifier` <a id=\"ct_custom\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_1 <= 56.00\n",
      "|   |--- feature_0 <= 40.50\n",
      "|   |   |--- feature_4 <= 269.00\n",
      "|   |   |   |--- value: [0]\n",
      "|   |   |--- feature_4 > 269.00\n",
      "|   |   |   |--- value: [1]\n",
      "|   |--- feature_0 > 40.50\n",
      "|   |   |--- value: [1]\n",
      "|--- feature_1 > 56.00\n",
      "|   |--- feature_2 <= 83.15\n",
      "|   |   |--- feature_4 <= 219.00\n",
      "|   |   |   |--- value: [0]\n",
      "|   |   |--- feature_4 > 219.00\n",
      "|   |   |   |--- value: [1]\n",
      "|   |--- feature_2 > 83.15\n",
      "|   |   |--- value: [1]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        35\n",
      "           1       0.71      0.71      0.71        14\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.80      0.80      0.80        49\n",
      "weighted avg       0.84      0.84      0.84        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создаем объект класса для построения модели дерева решений\n",
    "dtc_custom_model = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# обучаем\n",
    "dtc_custom_model.fit(X_train, y_train)\n",
    "# печатаем дерево\n",
    "dtc_custom_model.print_decision_tree()\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtc_custom_model.predict(X_test)\n",
    "# выводим общий отчет по метрикам\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение дерева решений с помощью класса из `sklearn.tree.DecisionTreeClassifier` <a id=\"ct_sklearn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_1 <= 56.00\n",
      "|   |--- feature_0 <= 40.50\n",
      "|   |   |--- feature_4 <= 269.00\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- feature_4 >  269.00\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- feature_0 >  40.50\n",
      "|   |   |--- class: 1\n",
      "|--- feature_1 >  56.00\n",
      "|   |--- feature_2 <= 83.15\n",
      "|   |   |--- feature_4 <= 219.00\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- feature_4 >  219.00\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- feature_2 >  83.15\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        35\n",
      "           1       0.71      0.71      0.71        14\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.80      0.80      0.80        49\n",
      "weighted avg       0.84      0.84      0.84        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# инициализируем модель дерева решений\n",
    "dtc_model = tree.DecisionTreeClassifier(\n",
    "    max_depth=3,\n",
    "    criterion='entropy', # критерий информативности\n",
    "    random_state=42 # генератор случайных чисел для совпадения результатов\n",
    ")\n",
    "\n",
    "# обучаем\n",
    "dtc_model.fit(X_train, y_train)\n",
    "\n",
    "# выводим дерево решений на экран в виде списка условий\n",
    "print(tree.export_text(decision_tree=dtc_model))\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtc_model.predict(X_test)\n",
    "# выводим общий отчет по метрикам\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Получились одинаковые деревья решений и одинаковые метрики. \\\n",
    "Из чего можно сделать вывод, что собственный алгоритм для классификации реализован в первом приближении корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений для бинарной классификации с использованием логистической регрессии <a id=\"logistic_tree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классе `./classes/DecisionTreeWithLogisticRegression.py` \\\n",
    "реализован алгоритм дерева решения для бинарной классификации, \\\n",
    "аналогично, как в классе `./classes/DecisionTree.py`\n",
    "\n",
    "Но в качестве плоскости, разделяющей выборки на 2 части,\\\n",
    "взят не предикат, а логистическая регрессия.\n",
    "\n",
    "Посмотрим, какой это даст результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                  |                  |                  |--> value: 0; samples: 94; impurity: 0.342\n",
      "|                  |                  |    samples: 94\n",
      "|                  |                  |--> impurity: 0.342\n",
      "|                  |                  |    predict: 0\n",
      "|                  |                  |                  |--> None\n",
      "|                  |    samples: 97\n",
      "|                  |--> impurity: 0.446\n",
      "|                  |    predict: 0\n",
      "|                  |                  |--> value: 1; samples: 3; impurity: -0.000\n",
      "|    samples: 145\n",
      "|--> impurity: 0.947\n",
      "|    predict: 0\n",
      "|                  |                  |--> value: 0; samples: 3; impurity: -0.000\n",
      "|                  |    samples: 48\n",
      "|                  |--> impurity: 0.414\n",
      "|                  |    predict: 1\n",
      "|                  |                  |                  |--> value: 0; samples: 1; impurity: -0.000\n",
      "|                  |                  |    samples: 45\n",
      "|                  |                  |--> impurity: 0.154\n",
      "|                  |                  |    predict: 1\n",
      "|                  |                  |                  |--> value: 1; samples: 44; impurity: -0.000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        35\n",
      "           1       0.85      0.79      0.81        14\n",
      "\n",
      "    accuracy                           0.90        49\n",
      "   macro avg       0.88      0.86      0.87        49\n",
      "weighted avg       0.90      0.90      0.90        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создаем объект класса модели\n",
    "dtlr_model = DecisionTreeWithLogisticRegression(max_depth=3)\n",
    "\n",
    "# обучаем\n",
    "dtlr_model.fit(X_train, y_train)\n",
    "# печатаем дерево\n",
    "dtlr_model.print_decision_tree()\n",
    "\n",
    "# делаем предсказание\n",
    "y_pred = dtlr_model.predict(X_test)\n",
    "# выводим общий отчет по метрикам\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При той же глубине дерева мы получили лучшие метрики, чем для классического дерева решений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение значений взвешенной неоднородности в первых вершинах полученных моделей для классификации <a id=\"weighted_impurity\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним значения **взвешенной неоднородности** $G(Q,\\ p)$ в результате деления первой вершины каждого из полученных деревьев.\n",
    "\n",
    "Взвешенную неоднородность считаем по следующей формуле.\n",
    "\n",
    "$$ G(Q,\\ p)=\\frac{N^{left}}{N}H(Q^{left})+\\frac{N^{right}}{N}H(Q^{right}) $$\n",
    "\n",
    "Где \n",
    "- $p$ - это условие деления выборки \\\n",
    "(предикат для классического дерева решений \\\n",
    "и обученная линейная регрессия для нашего эксперимента).\n",
    "- $Q = {(x, y)}$ - это множество из объектов  выборки (строк $x$) и ответом к ним $y$.\n",
    "- $N = |Q|$ - мощность этого множества (количество элементов  в нем).\n",
    "- По условию $p$ выборка разбивается на 2 части: $Q^{left}$ и $Q^{right}$. \\\n",
    "Полученные выборки соответственно имеют мощности (количество элементов) $N^{left}$ и $N^{right}$.\n",
    "- $H$ - это функция, по которой рассчитывается критерий информативности.\\\n",
    "В нашем случае для дерева классификации это энтропия Шеннона.\n",
    "\n",
    "Подсчет этого значения реализован в методе `__calculate_weighted_impurity` каждого из классов\\\n",
    "(`DecisionTreeClassifier` и `DecisionTreeWithLogisticRegression`) и подсчитывается для каждой вершины.\n",
    "\n",
    "Выведем значение только для первой вершины каждого дерева.\\\n",
    "Потому что гипотеза состоит в том, что с помощью линейной регрессии разделение будет лучше, чем с помощью предиката.\\\n",
    "И проверить мы это можем по первой вершине (далее разделение идет на другие выборки поэтому сравнение по внутренним вершинам будет некорректно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Взвешенная неоднородность после деления первой вершины дерева класса DecisionTreeClassifier\n",
      "0.6262600470433869\n"
     ]
    }
   ],
   "source": [
    "print('Взвешенная неоднородность после деления первой вершины дерева класса DecisionTreeClassifier')\n",
    "print(dtc_custom_model.decision_tree.weighted_impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Взвешенная неоднородность после деления первой вершины дерева класса DecisionTreeWithLogisticRegression\n",
      "0.43514101416319195\n"
     ]
    }
   ],
   "source": [
    "print('Взвешенная неоднородность после деления первой вершины дерева класса DecisionTreeWithLogisticRegression')\n",
    "print(dtlr_model.decision_tree.weighted_impurity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что для класса `DecisionTreeWithLogisticRegression` взвешенная неоднородность меньше, следовательно деление произведено лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод <a id=\"result\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование логистической регрессии в качестве условия для  разделения выборок при делении дерева дало лучший результат, чем условие деления по предикату.\n",
    "\n",
    "Также мы получили лучшие метрики для эксперементального класса.\n",
    "\n",
    "На большом объеме данных подобный подход будет скорее всего не оптимальным.\\\n",
    "Потому что для каждого узла нужно будет строить и хранить обученную логистическую регрессию и набор предсказаний."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
